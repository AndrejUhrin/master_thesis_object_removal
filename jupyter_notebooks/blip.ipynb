{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from IPython.display import display\n",
    "import cv2  \n",
    "from utils.clip import load_clip, classify_image\n",
    "from utils.owl import load_owl, detect_with_owl\n",
    "from utils.blip import load_blip, classify_boxes\n",
    "from utils.box_mask import enlarge_box, draw_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "owl_thresh  = 0.18\n",
    "box_scale   = 1.1\n",
    "font = ImageFont.truetype(\"/Library/fonts/Arial.ttf\", size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398154aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_clip, model_clip = load_clip()\n",
    "processor_owl,  model_owl  = load_owl()\n",
    "processor_blip, model_blip = load_blip()\n",
    "print(\"Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"../pipeline_optimization_dataset/1CzPt_pZhdvbAhtM32ImlzZxtqsaFQ76j__Gewerberaum_III_UG.jpg\")\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels_outside = [[\n",
    "    \"a house number\", \"a license plate\", \"person\", \"a face\",\n",
    "    \"a religious symbol\", \"a political symbol\", \"a cat\", \"a dog\",\n",
    "]]\n",
    "text_labels_inside = [[\n",
    "    \"a calendar\", \"a license plate\", \"a paper\", \"person\",\n",
    "    \"a framed picture\", \"a picture\", \"a poster board\",\n",
    "    \"a name\", \"a face\", \"a religious symbol\", \"a political symbol\",\n",
    "    \"a sex toy\", \"a nude image\", \"a cat\", \"a dog\",\n",
    "    \"a mirror\", \"a window\", \"a television\"\n",
    "]]\n",
    "per_label_thresh = {\n",
    "    \"a calendar\": 0.20, \"a paper\": 0.20, \"a house number\": 0.21,\n",
    "    \"a license plate\": 0.19, \"person\": 0.20, \"a framed picture\": 0.22,\n",
    "    \"a picture\": 0.22, \"a poster board\": 0.30, \"a name\": 0.20,\n",
    "    \"a face\": 0.20, \"a religious symbol\": 0.24, \"a political symbol\": 0.20,\n",
    "    \"a sex toy\": 0.23, \"a nude image\": 0.30, \"a cat\": 0.28, \"a dog\": 0.28,\n",
    "    \"a mirror\": 0.30, \"a window\": 0.30, \"a television\": 0.50\n",
    "}\n",
    "default_thresh = owl_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h  = image.size\n",
    "inout = classify_image(image, processor_clip, model_clip)\n",
    "labs  = text_labels_inside if inout == \"an indoor scene\" else text_labels_outside\n",
    "print(\"Scene classification:\", inout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62115ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_p, scores, labels = detect_with_owl(image, labs, processor_owl, model_owl, threshold=owl_thresh)\n",
    "raw_boxes = [b.tolist() for b in boxes_p]\n",
    "\n",
    "annotated_pre = draw_annotated(image.copy(), raw_boxes, [float(s.item()) for s in scores], labels, font=font)\n",
    "display(annotated_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe66741",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = [\n",
    "    (b, s, l) for b, s, l in zip(raw_boxes, scores, labels)\n",
    "    if s.item() >= per_label_thresh.get(l, default_thresh)\n",
    "]\n",
    "if kept:\n",
    "    boxes_f, scores_f, labels_f = map(list, zip(*kept))\n",
    "else:\n",
    "    boxes_f, scores_f, labels_f = [], [], []\n",
    "    print(\"No boxes after score filter.\")\n",
    "\n",
    "if boxes_f:\n",
    "    person_or_nude = {\"person\", \"a nude image\"}\n",
    "    always_drop    = {\"a television\", \"a window\", \"a mirror\"}\n",
    "    remove_idx = set()\n",
    "\n",
    "    for i, lab in enumerate(labels_f):\n",
    "        if lab in always_drop:\n",
    "            remove_idx.add(i)\n",
    "\n",
    "    for i, (box_i, lab_i) in enumerate(zip(boxes_f, labels_f)):\n",
    "        if lab_i not in (\"a television\", \"a window\"):\n",
    "            continue\n",
    "        x0, y0, x1, y1 = box_i\n",
    "        Ai = max(0, x1 - x0) * max(0, y1 - y0)\n",
    "        if Ai == 0:\n",
    "            continue\n",
    "        for j, (box_j, lab_j) in enumerate(zip(boxes_f, labels_f)):\n",
    "            if j == i: \n",
    "                continue\n",
    "            x0j, y0j, x1j, y1j = box_j\n",
    "            iw = max(0, min(x1, x1j) - max(x0, x0j))\n",
    "            ih = max(0, min(y1, y1j) - max(y0, y0j))\n",
    "            if iw * ih == 0:\n",
    "                continue\n",
    "            overlap_ratio = (iw * ih) / Ai\n",
    "            if lab_j in person_or_nude:\n",
    "                continue\n",
    "            if overlap_ratio >= 0.20:\n",
    "                remove_idx.add(j)\n",
    "\n",
    "    filtered = [\n",
    "        (b, s, l)\n",
    "        for k, (b, s, l) in enumerate(zip(boxes_f, scores_f, labels_f))\n",
    "        if k not in remove_idx\n",
    "    ]\n",
    "    if filtered:\n",
    "        boxes_f, scores_f, labels_f = map(list, zip(*filtered))\n",
    "    else:\n",
    "        boxes_f, scores_f, labels_f = [], [], []\n",
    "\n",
    "post_enl = [enlarge_box(box=b, scale=box_scale, img_w=w, img_h=h) for b in boxes_f]\n",
    "\n",
    "annotated_post = draw_annotated(image.copy(), post_enl, [s.item() for s in scores_f], labels_f, font=font)\n",
    "display(annotated_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459050cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not post_enl:\n",
    "    print(\"No boxes to classify with BLIP.\")\n",
    "else:\n",
    "    actions: List[str] = []\n",
    "\n",
    "    def expand_box(box, scale, img_w, img_h, min_crop_size=None):\n",
    "        x0, y0, x1, y1 = box\n",
    "        w_box = x1 - x0\n",
    "        h_box = y1 - y0\n",
    "        cx = x0 + w_box / 2.0\n",
    "        cy = y0 + h_box / 2.0\n",
    "\n",
    "        new_w = w_box * scale\n",
    "        new_h = h_box * scale\n",
    "\n",
    "        if min_crop_size is not None:\n",
    "            if new_w < min_crop_size:\n",
    "                new_w = min_crop_size\n",
    "            if new_h < min_crop_size:\n",
    "                new_h = min_crop_size\n",
    "\n",
    "        x0n = max(0, int(round(cx - new_w / 2.0)))\n",
    "        y0n = max(0, int(round(cy - new_h / 2.0)))\n",
    "        x1n = min(img_w, int(round(cx + new_w / 2.0)))\n",
    "        y1n = min(img_h, int(round(cy + new_h / 2.0)))\n",
    "        return [x0n, y0n, x1n, y1n]\n",
    "\n",
    "    expand_factor = 1.4\n",
    "    min_crop_size = 250  \n",
    "    if inout != \"an indoor scene\":\n",
    "        for lbl in labels_f:\n",
    "            if lbl in (\"a license plate\", \"license plate\"):\n",
    "                actions.append(\"blur\")\n",
    "            else:\n",
    "                actions.append(\"inpaint\")\n",
    "\n",
    "        print(\"Actions (outdoor heuristic):\")\n",
    "        for b, l, a in zip(post_enl, labels_f, actions):\n",
    "            print(f\"{l:>18} -> {a}\")\n",
    "\n",
    "    else:\n",
    "        blip_boxes = []\n",
    "        blip_indices = []\n",
    "        expanded_crops = []\n",
    "\n",
    "        img_w, img_h = image.size\n",
    "\n",
    "        for i, lbl in enumerate(labels_f):\n",
    "            if lbl == \"person\":\n",
    "                actions.append(\"inpaint\")\n",
    "            else:\n",
    "                blip_indices.append(i)\n",
    "                original_box = post_enl[i]\n",
    "                blip_boxes.append(original_box)\n",
    "                actions.append(None)  \n",
    "                exp_box = expand_box(\n",
    "                    original_box, expand_factor, img_w, img_h, min_crop_size=min_crop_size\n",
    "                )\n",
    "                expanded_crops.append(exp_box)\n",
    "\n",
    "        if blip_boxes:\n",
    "            blip_results = classify_boxes(\n",
    "                image,\n",
    "                blip_boxes,\n",
    "                processor_blip,\n",
    "                model_blip,\n",
    "                expand_factor=expand_factor,\n",
    "                min_crop_size=min_crop_size\n",
    "            )\n",
    "            for idx_rel, act in enumerate(blip_results):\n",
    "                idx_abs = blip_indices[idx_rel]\n",
    "                actions[idx_abs] = act\n",
    "\n",
    "        for i, a in enumerate(actions):\n",
    "            if a is None:\n",
    "                actions[i] = \"blur\"\n",
    "\n",
    "        if blip_boxes:\n",
    "            print(f\"Displaying {len(expanded_crops)} expanded (x{expand_factor}) BLIP crops:\")\n",
    "            for (orig_idx, exp_box, act) in zip(blip_indices, expanded_crops,\n",
    "                                                [actions[i] for i in blip_indices]):\n",
    "                x0e, y0e, x1e, y1e = exp_box\n",
    "                crop_img = image.crop((x0e, y0e, x1e, y1e))\n",
    "                print(f\"Box #{orig_idx} label={labels_f[orig_idx]} action={act} expanded_box={exp_box}\")\n",
    "                display(crop_img)\n",
    "\n",
    "        print(\"Final actions (indoor):\")\n",
    "        for b, l, a in zip(post_enl, labels_f, actions):\n",
    "            print(f\"{l:>18} -> {a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad28055",
   "metadata": {},
   "outputs": [],
   "source": [
    "if post_enl:\n",
    "    class_annot = image.copy()\n",
    "    draw_cls = ImageDraw.Draw(class_annot)\n",
    "\n",
    "    for (x0, y0, x1, y1), lbl, act in zip(post_enl, labels_f, actions):\n",
    "        color = \"blue\" if act in (\"inpaint\", \"free\") else \"red\"\n",
    "        draw_cls.rectangle([x0, y0, x1, y1], outline=color, width=4)\n",
    "        tag = f\"{lbl}, {act}\"\n",
    "        tw, th = draw_cls.textbbox((0, 0), tag, font=font)[2:]\n",
    "        draw_cls.rectangle([x0, y0 - th - 4, x0 + tw + 4, y0], fill=\"white\")\n",
    "        draw_cls.text((x0 + 2, y0 - th - 2), tag, fill=color, font=font)\n",
    "\n",
    "    display(class_annot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lama_object_removal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

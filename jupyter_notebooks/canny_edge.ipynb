{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "project_root = Path(\".\").resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.clip import load_clip, classify_image\n",
    "from utils.owl import load_owl, detect_with_owl\n",
    "from utils.sam import load_sam, segment_with_sam, post_process_sam_masks\n",
    "from utils.mask import create_black_white_mask\n",
    "from utils.box_mask import enlarge_box, draw_annotated\n",
    "from utils.opencv_canny import analyze_segmentation_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "owl_thresh  = 0.18\n",
    "box_scale   = 1.1\n",
    "font = ImageFont.truetype(\"/Library/fonts/Arial.ttf\", size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571fb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_clip, model_clip = load_clip()\n",
    "processor_owl,  model_owl  = load_owl()\n",
    "processor_sam,  model_sam  = load_sam()\n",
    "print(\"Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"../pipeline_optimization_dataset/1SIka2FSC_tE6_94GW3GsRvb-Gi5CA8wa__KuÌˆche_Wohnung1.jpg\")\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels_outside = [[\n",
    "    \"a house number\", \"a license plate\", \"person\", \"a face\",\n",
    "    \"a religious symbol\", \"a political symbol\", \"a cat\", \"a dog\",\n",
    "]]\n",
    "text_labels_inside = [[\n",
    "    \"a calendar\", \"a license plate\", \"a paper\", \"person\",\n",
    "    \"a framed picture\", \"a picture\", \"a poster board\",\n",
    "    \"a name\", \"a face\", \"a religious symbol\", \"a political symbol\",\n",
    "    \"a sex toy\", \"a nude image\", \"a cat\", \"a dog\",\n",
    "    \"a mirror\", \"a window\", \"a television\"\n",
    "]]\n",
    "per_label_thresh = {\n",
    "    \"a calendar\": 0.20, \"a paper\": 0.20, \"a house number\": 0.21,\n",
    "    \"a license plate\": 0.19, \"person\": 0.20, \"a framed picture\": 0.22,\n",
    "    \"a picture\": 0.22, \"a poster board\": 0.30, \"a name\": 0.20,\n",
    "    \"a face\": 0.20, \"a religious symbol\": 0.24, \"a political symbol\": 0.20,\n",
    "    \"a sex toy\": 0.23, \"a nude image\": 0.30, \"a cat\": 0.28, \"a dog\": 0.28,\n",
    "    \"a mirror\": 0.30, \"a window\": 0.30, \"a television\": 0.50\n",
    "}\n",
    "default_thresh = owl_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24117139",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h  = image.size\n",
    "inout = classify_image(image, processor_clip, model_clip)\n",
    "labs  = text_labels_inside if inout == \"an indoor scene\" else text_labels_outside\n",
    "print(\"Scene classification:\", inout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_p, scores, labels = detect_with_owl(image, labs, processor_owl, model_owl, threshold=owl_thresh)\n",
    "raw_boxes = [b.tolist() for b in boxes_p]\n",
    "\n",
    "annotated_pre = draw_annotated(image.copy(), raw_boxes, [float(s.item()) for s in scores], labels, font=font)\n",
    "display(annotated_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ac350",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = [\n",
    "    (b, s, l) for b, s, l in zip(raw_boxes, scores, labels)\n",
    "    if s.item() >= per_label_thresh.get(l, default_thresh)\n",
    "]\n",
    "if kept:\n",
    "    boxes_f, scores_f, labels_f = map(list, zip(*kept))\n",
    "else:\n",
    "    boxes_f, scores_f, labels_f = [], [], []\n",
    "    print(\"No boxes after score filter.\")\n",
    "\n",
    "# Overlap logic\n",
    "if boxes_f:\n",
    "    person_or_nude = {\"person\", \"a nude image\"}\n",
    "    always_drop    = {\"a television\", \"a window\", \"a mirror\"}\n",
    "    remove_idx = set()\n",
    "\n",
    "    for i, lab in enumerate(labels_f):\n",
    "        if lab in always_drop:\n",
    "            remove_idx.add(i)\n",
    "\n",
    "    for i, (box_i, lab_i) in enumerate(zip(boxes_f, labels_f)):\n",
    "        if lab_i not in (\"a television\", \"a window\"):\n",
    "            continue\n",
    "        x0, y0, x1, y1 = box_i\n",
    "        Ai = max(0, x1 - x0) * max(0, y1 - y0)\n",
    "        if Ai == 0:\n",
    "            continue\n",
    "        for j, (box_j, lab_j) in enumerate(zip(boxes_f, labels_f)):\n",
    "            if j == i: \n",
    "                continue\n",
    "            x0j, y0j, x1j, y1j = box_j\n",
    "            iw = max(0, min(x1, x1j) - max(x0, x0j))\n",
    "            ih = max(0, min(y1, y1j) - max(y0, y0j))\n",
    "            if iw * ih == 0:\n",
    "                continue\n",
    "            overlap_ratio = (iw * ih) / Ai\n",
    "            if lab_j in person_or_nude:\n",
    "                continue\n",
    "            if overlap_ratio >= 0.20:\n",
    "                remove_idx.add(j)\n",
    "\n",
    "    filtered = [\n",
    "        (b, s, l)\n",
    "        for k, (b, s, l) in enumerate(zip(boxes_f, scores_f, labels_f))\n",
    "        if k not in remove_idx\n",
    "    ]\n",
    "    if filtered:\n",
    "        boxes_f, scores_f, labels_f = map(list, zip(*filtered))\n",
    "    else:\n",
    "        boxes_f, scores_f, labels_f = [], [], []\n",
    "\n",
    "post_enl = [enlarge_box(box=b, scale=box_scale, img_w=w, img_h=h) for b in boxes_f]\n",
    "\n",
    "annotated_post = draw_annotated(image.copy(), post_enl, [s.item() for s in scores_f], labels_f, font=font)\n",
    "display(annotated_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b549a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not post_enl:\n",
    "    print(\"No boxes to run SAM on. Stop here.\")\n",
    "else:\n",
    "    tb = torch.tensor(post_enl, dtype=torch.float32).unsqueeze(0)\n",
    "    outs, ins = segment_with_sam(image, tb, processor_sam, model_sam)\n",
    "    masks_from_sam = post_process_sam_masks(outs, processor_sam, ins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if post_enl:\n",
    "    mask10 = create_black_white_mask(masks_from_sam, threshold=0.5, combine=True,dilation_px=10)\n",
    "    display(mask10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de724140",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray       = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "edges      = cv2.Canny(gray, 100, 200)\n",
    "edge_color = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "mask_np = (np.array(mask10.convert(\"L\")) > 127).astype(np.uint8)\n",
    "contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "margin = 60\n",
    "kernel = cv2.getStructuringElement(\n",
    "    cv2.MORPH_ELLIPSE,\n",
    "    (2*margin + 1, 2*margin + 1)\n",
    ")\n",
    "\n",
    "for cnt in contours:\n",
    "    single_mask = np.zeros_like(mask_np, dtype=np.uint8)\n",
    "    cv2.drawContours(single_mask, [cnt], -1, color=1, thickness=-1)\n",
    "\n",
    "    dilated_mask = cv2.dilate(single_mask, kernel, iterations=1)\n",
    "\n",
    "    dilated_cnts, _ = cv2.findContours(\n",
    "        dilated_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    cv2.drawContours(edge_color, [cnt], -1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.drawContours(edge_color, dilated_cnts, -1, (0, 255, 0), 2)\n",
    "\n",
    "display(Image.fromarray(edge_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ce749",
   "metadata": {},
   "outputs": [],
   "source": [
    "if post_enl:\n",
    "    is_outdoor = (inout != \"an indoor scene\")\n",
    "    always_inpaint_indoor = {\"person\", \"a religious symbol\", \"a political symbol\"}\n",
    "\n",
    "    sam_bool_masks = [\n",
    "        (np.array(m) > 0.5).astype(np.uint8) for m in masks_from_sam\n",
    "    ]\n",
    "\n",
    "    bw10_cv = np.array(mask10.convert(\"L\"))\n",
    "    mask10_binary = (bw10_cv > 127).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask10_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    print(f\"Objects in 10px mask: {len(contours)}\")\n",
    "\n",
    "    classified_contours = []\n",
    "    image_for_canny = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        single_mask = np.zeros_like(mask10_binary)\n",
    "        cv2.drawContours(single_mask, [cnt], -1, color=1, thickness=-1)\n",
    "\n",
    "        overlaps = [\n",
    "            np.logical_and(single_mask, sam_bool_masks[j]).sum()\n",
    "            for j in range(len(sam_bool_masks))\n",
    "        ]\n",
    "        obj_idx = int(np.argmax(overlaps))\n",
    "        lbl     = labels_f[obj_idx]\n",
    "\n",
    "        if is_outdoor:\n",
    "            action     = \"blur\" if lbl == \"a license plate\" else \"inpaint\"\n",
    "            edge_ratio = float(\"nan\")\n",
    "        else:\n",
    "            if lbl in always_inpaint_indoor:\n",
    "                action, edge_ratio = \"inpaint\", float(\"nan\")\n",
    "            else:\n",
    "                result = analyze_segmentation_edges(\n",
    "                    image_for_canny,\n",
    "                    single_mask.astype(bool),\n",
    "                    margin=60,\n",
    "                    edge_threshold=0.015\n",
    "                )[0]\n",
    "                action     = result[\"action\"]\n",
    "                edge_ratio = result[\"edge_ratio\"]\n",
    "\n",
    "        er_str = f\"{edge_ratio:.3f}\" if edge_ratio == edge_ratio else \"â€”\"\n",
    "        classified_contours.append({\n",
    "            \"contour\": cnt,\n",
    "            \"action\": action,\n",
    "            \"edge_ratio\": edge_ratio\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c80767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if post_enl:\n",
    "    annotated_image = image.copy()\n",
    "    draw = ImageDraw.Draw(annotated_image)\n",
    "\n",
    "    for item in classified_contours:\n",
    "        cnt = item['contour']\n",
    "        action = item['action']\n",
    "        edge_ratio = item['edge_ratio']\n",
    "\n",
    "        color = \"red\" if action == \"blur\" else \"blue\"\n",
    "        pts = [tuple(pt[0]) for pt in cnt]\n",
    "        draw.line(pts + [pts[0]], fill=color, width=3)\n",
    "\n",
    "        x, y, w0, h0 = cv2.boundingRect(cnt)\n",
    "        label_txt = f\"{action}, {edge_ratio:.3f}\" if edge_ratio == edge_ratio else action\n",
    "        text_w = font.getlength(label_txt)\n",
    "        text_h = font.size\n",
    "\n",
    "        draw.rectangle([x, y - text_h - 6, x + text_w + 10, y], fill=\"black\")\n",
    "        draw.text((x + 5, y - text_h - 3), label_txt, font=font, fill=\"white\")\n",
    "\n",
    "    display(annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af8101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc672a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lama_object_removal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

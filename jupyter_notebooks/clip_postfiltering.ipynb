{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "project_root = Path(\".\").resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.clip import load_clip, classify_image\n",
    "from utils.owl import load_owl, detect_with_owl\n",
    "from utils.box_mask import enlarge_box, draw_annotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d133dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "owl_thresh  = 0.18\n",
    "box_scale   = 1.1\n",
    "font = ImageFont.truetype(\"/Library/fonts/Arial.ttf\", size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_clip, model_clip = load_clip()\n",
    "processor_owl,  model_owl  = load_owl()\n",
    "print(\"Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"../pipeline_optimization_dataset/1SIka2FSC_tE6_94GW3GsRvb-Gi5CA8wa__KuÌˆche_Wohnung1.jpg\")\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels_outside = [[\n",
    "    \"a house number\", \"a license plate\", \"person\", \"a face\",\n",
    "    \"a religious symbol\", \"a political symbol\", \"a cat\", \"a dog\",\n",
    "]]\n",
    "text_labels_inside = [[\n",
    "    \"a calendar\", \"a license plate\", \"a paper\", \"person\",\n",
    "    \"a framed picture\", \"a picture\", \"a poster board\",\n",
    "    \"a name\", \"a face\", \"a religious symbol\", \"a political symbol\",\n",
    "    \"a sex toy\", \"a nude image\", \"a cat\", \"a dog\",\n",
    "    \"a mirror\", \"a window\", \"a television\"\n",
    "]]\n",
    "per_label_thresh = {\n",
    "    \"a calendar\": 0.20, \"a paper\": 0.20, \"a house number\": 0.21,\n",
    "    \"a license plate\": 0.19, \"person\": 0.20, \"a framed picture\": 0.22,\n",
    "    \"a picture\": 0.22, \"a poster board\": 0.30, \"a name\": 0.20,\n",
    "    \"a face\": 0.20, \"a religious symbol\": 0.24, \"a political symbol\": 0.20,\n",
    "    \"a sex toy\": 0.23, \"a nude image\": 0.30, \"a cat\": 0.28, \"a dog\": 0.28,\n",
    "    \"a mirror\": 0.30, \"a window\": 0.30, \"a television\": 0.50\n",
    "}\n",
    "default_thresh = owl_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h  = image.size\n",
    "inout = classify_image(image, processor_clip, model_clip)\n",
    "labs  = text_labels_inside if inout == \"an indoor scene\" else text_labels_outside\n",
    "print(\"Scene classification:\", inout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df037254",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_p, scores, labels = detect_with_owl(image, labs, processor_owl, model_owl, threshold=owl_thresh)\n",
    "raw_boxes = [b.tolist() for b in boxes_p]\n",
    "\n",
    "annotated_pre = draw_annotated(image.copy(), raw_boxes, [float(s.item()) for s in scores], labels, font=font)\n",
    "display(annotated_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = [\n",
    "    (b, s, l) for b, s, l in zip(raw_boxes, scores, labels)\n",
    "    if s.item() >= per_label_thresh.get(l, default_thresh)\n",
    "]\n",
    "if kept:\n",
    "    boxes_f, scores_f, labels_f = map(list, zip(*kept))\n",
    "else:\n",
    "    boxes_f, scores_f, labels_f = [], [], []\n",
    "    print(\"No boxes after score filter.\")\n",
    "\n",
    "if boxes_f:\n",
    "    person_or_nude = {\"person\", \"a nude image\"}\n",
    "    always_drop    = {\"a television\", \"a window\", \"a mirror\"}\n",
    "    remove_idx = set()\n",
    "\n",
    "    for i, lab in enumerate(labels_f):\n",
    "        if lab in always_drop:\n",
    "            remove_idx.add(i)\n",
    "\n",
    "    for i, (box_i, lab_i) in enumerate(zip(boxes_f, labels_f)):\n",
    "        if lab_i not in (\"a television\", \"a window\"):\n",
    "            continue\n",
    "        x0, y0, x1, y1 = box_i\n",
    "        Ai = max(0, x1 - x0) * max(0, y1 - y0)\n",
    "        if Ai == 0:\n",
    "            continue\n",
    "        for j, (box_j, lab_j) in enumerate(zip(boxes_f, labels_f)):\n",
    "            if j == i: \n",
    "                continue\n",
    "            x0j, y0j, x1j, y1j = box_j\n",
    "            iw = max(0, min(x1, x1j) - max(x0, x0j))\n",
    "            ih = max(0, min(y1, y1j) - max(y0, y0j))\n",
    "            if iw * ih == 0:\n",
    "                continue\n",
    "            overlap_ratio = (iw * ih) / Ai\n",
    "            if lab_j in person_or_nude:\n",
    "                continue\n",
    "            if overlap_ratio >= 0.20:\n",
    "                remove_idx.add(j)\n",
    "\n",
    "    filtered = [\n",
    "        (b, s, l)\n",
    "        for k, (b, s, l) in enumerate(zip(boxes_f, scores_f, labels_f))\n",
    "        if k not in remove_idx\n",
    "    ]\n",
    "    \n",
    "    if filtered:\n",
    "        boxes_f, scores_f, labels_f = map(list, zip(*filtered))\n",
    "    else:\n",
    "        boxes_f, scores_f, labels_f = [], [], []\n",
    "\n",
    "post_enl = [enlarge_box(box=b, scale=box_scale, img_w=w, img_h=h) for b in boxes_f]\n",
    "\n",
    "annotated_post = draw_annotated(image.copy(), post_enl, [s.item() for s in scores_f], labels_f, font=font)\n",
    "display(annotated_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c107921",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_labels = {\n",
    "    \"a house number\", \"a political symbol\", \"a family picture\", \"a picture frame\",\n",
    "    \"a canvas\", \"a picture\", \"a paper\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_multi(crop, prompts):\n",
    "    \"\"\"Run CLIP zero-shot classification on the given crop.\"\"\"\n",
    "    inputs = processor_clip(text=prompts, images=crop, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model_clip(**inputs).logits_per_image.squeeze(0)\n",
    "        probs  = torch.softmax(logits, dim=0)\n",
    "    probs_list = probs.tolist()\n",
    "    return int(torch.argmax(probs).item()), probs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_prompts(label: str):\n",
    "    if label == \"a house number\":\n",
    "        return [\"a digits on a wall\", \"a house number\", \"a number\"], [\"a blank wall without digits\", \"a door or window\", \"decoration\",\"a street sign with text\"]\n",
    "    elif label == \"a political symbol\":\n",
    "        return [\"a flag\", \"a political symbol\"], [\"a traffic sign\", \"an advertisement poster\"]\n",
    "    elif label == \"a framed picture\":\n",
    "        return [\"a framed picture\", \"a photograph\"], [\"a pianting\", \"an artwork\", \"a wooden board\", \"a blank wall\", \"a door\", \"a window\", \"a television\"]\n",
    "    elif label == \"a picture\":\n",
    "        return [\"a picture\", \"a photograph\", \"a framed picture\"], [\"a pianting\", \"an artwork\",\"a wooden board\", \"a blank wall\", \"a door\", \"a window\", \"a television\"]\n",
    "    elif label == \"a paper\":\n",
    "        return [\"a paper\"], [\"a book\", \"a folder\"]\n",
    "    return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ce517",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_dicts = [{\"box\": box, \"label\": label, \"score\": score} for box, score, label in kept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85994820",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_clip = []          \n",
    "for det in kept_dicts:\n",
    "    lbl = det[\"label\"]\n",
    "    det[\"clip_pass\"] = True            \n",
    "\n",
    "    if lbl in clip_labels:\n",
    "        if lbl in {\"a house number\", \"a political symbol\"} and inout == \"an outdoor scene\":\n",
    "            x0, y0, x1, y1 = map(int, det[\"box\"])\n",
    "            crop = image.crop((x0, y0, x1, y1))\n",
    "            pos, neg = get_clip_prompts(lbl)\n",
    "            prompts = pos + neg\n",
    "            if prompts:\n",
    "                win_idx, confs = clip_multi(crop, prompts)\n",
    "                det[\"clip_pass\"] = win_idx < len(pos)\n",
    "        elif lbl not in {\"a house number\", \"a political symbol\"}:\n",
    "            x0, y0, x1, y1 = map(int, det[\"box\"])\n",
    "            crop = image.crop((x0, y0, x1, y1))\n",
    "            pos, neg = get_clip_prompts(lbl)\n",
    "            prompts = pos + neg\n",
    "            if prompts:\n",
    "                win_idx, confs = clip_multi(crop, prompts)\n",
    "                det[\"clip_pass\"] = win_idx < len(pos)\n",
    "\n",
    "    if det[\"clip_pass\"]:\n",
    "        if crop is None:  \n",
    "            x0, y0, x1, y1 = map(int, det[\"box\"])\n",
    "            crop = image.crop((x0, y0, x1, y1))\n",
    "        display(crop) \n",
    "        kept_clip.append(det)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kept_clip:  \n",
    "     annotated_clip = draw_annotated(image, [d[\"box\"]   for d in kept_clip], [d[\"score\"] for d in kept_clip], [d[\"label\"] for d in kept_clip], font=font)\n",
    "     display(annotated_clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lama_object_removal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
